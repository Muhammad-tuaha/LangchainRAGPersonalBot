{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:27.921486Z",
     "start_time": "2025-07-30T13:31:25.221897Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "#lets start RAG\n",
    "#injestion -> bringing data in the system in the form of pdf,csv,json etc\n",
    "\n",
    "#loaders -> splitter -> embeddings-> index\n",
    "\n",
    "!pip install langchain"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\uvicorn\\server.py:69> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\uvicorn\\main.py\", line 580, in run\n",
      "    server.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\uvicorn\\server.py\", line 67, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Taha\\Anaconda\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Taha\\Anaconda\\Lib\\asyncio\\tasks.py\", line 386, in __wakeup\n",
      "    self.__step()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Taha\\Anaconda\\Lib\\asyncio\\tasks.py\", line 293, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\Taha\\Anaconda\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\uvicorn\\server.py\", line 70, in serve\n",
      "    with self.capture_signals():\n",
      "         ~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\Taha\\Anaconda\\Lib\\contextlib.py\", line 148, in __exit__\n",
      "    next(self.gen)\n",
      "    ~~~~^^^^^^^^^^\n",
      "  File \"C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages\\uvicorn\\server.py\", line 331, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:33.692363Z",
     "start_time": "2025-07-30T13:31:27.941748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install pypdf\n",
    "!pip install langchain_community\n",
    "%pip install -qU langchain_community pypdf"
   ],
   "id": "3e73e8ce0c771850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (5.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain_community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:33.844688Z",
     "start_time": "2025-07-30T13:31:33.709200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "filePath=\"C:\\\\Users\\\\Taha\\\\Personal\\\\Final_Taha_AI_Resume.pdf\"\n",
    "\n",
    "pdfLoader=PyPDFLoader(filePath)"
   ],
   "id": "212197dd48b3e3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:34.125273Z",
     "start_time": "2025-07-30T13:31:33.860837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PdfDocs=pdfLoader.load()\n",
    "PdfDocs[0]"
   ],
   "id": "c6eb3bf95a65edd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-02T23:51:47+05:00', 'author': 'python-docx', 'moddate': '2025-06-02T23:51:47+05:00', 'source': 'C:\\\\Users\\\\Taha\\\\Personal\\\\Final_Taha_AI_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Muhammad Taha  \\nEmail: tahasoomro10@gmail.com               LinkedIn: www.linkedin.com/in/muhammad-taha-cs  \\nGitHub: https://github.com/Muhammad-tuaha       contact : +923105288105 \\n  \\nEducation \\nAir University, Islamabad \\nBachelor of Science in Computer Science (2023–2027) \\nCertifications \\nMachine Learning Specialization (In Progress) \\nCoursera / DeepLearning.AI \\n- Topics: Supervised learning, model evaluation, linear/logistic regression, gradient descent, regularization. \\nSkills / Achievements \\nProgramming: Python, C#, C++, JavaScript \\nBackend/Tools: Node.js, Express.js, MongoDB, Git \\nAI/ML Concepts: Supervised Learning, Model Evaluation (in-progress knowledge) \\nSoft Skills: Teamwork, Self-learning, Critical Thinking, Time Management \\nProjects / Experience \\n❖ GitHub Simulation Using DSA Algorithms – C++ \\nDeveloped a console-based simulation of core GitHub functionalities by leveraging advanced data structures and algorithms. \\nApplied stacks, queues, and linked lists to effectively replicate version control processes, pull requests, and commit history \\nmanagement. \\n❖ Anomaly Detection & DDoS Prevention System \\nDesigned and executed an anomaly detection system in Python using supervised machine learning with Random Forest. \\nSuccessfully isolated normal website traffic from malicious activity, demonstrating strong application of security principles in a \\nreal-world information security project. \\n❖ NFT Marketplace in Blazor .NET \\nBuilt a robust full-stack NFT marketplace utilizing Blazor for the frontend, C# for backend logic, and SQL Server for database \\nmanagement. Implemented secure user authentication, dynamic item listings, and real-time bidding with comprehensive CRUD \\noperations, ensuring seamless and secure user experience. \\n❖ NFT Marketplace Backend in JavaScript \\nDeveloped the backend API for an NFT marketplace using Express.js and MongoDB, expertly handling routing, database integration, \\nand RESTful services to support marketplace functionalities. \\n❖ Smart Home System Simulation \\nCreated a smart home system simulation using Python socket programming to control electrical devices remotely from a central \\nserver. This project demonstrated practical networking concepts and real-time device management as part of a computer networks \\ncourse. \\nAbout me \\nAspiring Machine Learning Intern and Computer Science student at Air University (2023–2027), with strong foundational knowledge in \\nPython, C++, and backend development. Currently pursuing the Coursera Machine Learning Specialization by DeepLearning.AI. Highly \\nmotivated to apply and grow skills in real-world AI/ML projects through hands-on internship opportunities.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:36.413038Z",
     "start_time": "2025-07-30T13:31:34.143596Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -qU langchain_community beautifulsoup4",
   "id": "63311e9c8b4a14f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:36.433432Z",
     "start_time": "2025-07-30T13:31:36.430216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# loader = WebBaseLoader(\"https://www.quettacafe.com/\")"
   ],
   "id": "7b9c99460fd2341",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:36.456347Z",
     "start_time": "2025-07-30T13:31:36.453108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# docs=loader.load()\n",
    "# webData=loader.load()\n",
    "#\n",
    "# docs[0]\n"
   ],
   "id": "adaacea766b2653e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:36.476380Z",
     "start_time": "2025-07-30T13:31:36.472903Z"
    }
   },
   "cell_type": "code",
   "source": "# print(docs[0].metadata)",
   "id": "b29afeffc8181b01",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:36.489055Z",
     "start_time": "2025-07-30T13:31:36.485463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_text_splitters import CharacterTextSplitter\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator=[\"\\n\\n\"],\n",
    "#     chunk_size=100,\n",
    "#     chunk_overlap=100\n",
    "# )\n",
    "#\n",
    "# all_text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "# texts = text_splitter.split_text(all_text)\n",
    "# texts[1]\n"
   ],
   "id": "6ac6758c269cce",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:38.110127Z",
     "start_time": "2025-07-30T13:31:36.506629Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tiktoken\n",
   "id": "26b1f8998525b51a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taha\\pycharmprojects\\langchainagent\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:38.129153Z",
     "start_time": "2025-07-30T13:31:38.125368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter( separators=[\"\\n\\n\",\"\\n\",\" \"],chunk_size=200, chunk_overlap=20)\n",
    "#\n",
    "# all_text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "# texts = text_splitter.split_text(all_text)\n",
    "#\n",
    "# print(f\"{texts[0]}\\n|| {texts[4]}\")\n"
   ],
   "id": "fa31e136143b5126",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:31:40.625973Z",
     "start_time": "2025-07-30T13:31:38.148161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#now lets create embeddings\n",
    "\n",
    "%pip install --upgrade --quiet  langchain langchain-huggingface sentence_transformers"
   ],
   "id": "e74a23d3ca104573",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:23.520988Z",
     "start_time": "2025-07-30T13:31:40.644213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]\n",
    "doc_result = embeddings.embed_documents([text])"
   ],
   "id": "149863ddf0a0256e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:25.248710Z",
     "start_time": "2025-07-30T13:32:23.538821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install --quiet langchain_experimental langchain_openai"
   ],
   "id": "9cb6f31b555e2d4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:30.363397Z",
     "start_time": "2025-07-30T13:32:25.266728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lets try semantic splitter/chunker\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddingModel = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "Splitter = SemanticChunker(embeddingModel)\n",
    "chunks=Splitter.split_documents(PdfDocs)\n",
    "print(chunks[0].metadata)"
   ],
   "id": "de13d7ef6ae3e46d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-02T23:51:47+05:00', 'author': 'python-docx', 'moddate': '2025-06-02T23:51:47+05:00', 'source': 'C:\\\\Users\\\\Taha\\\\Personal\\\\Final_Taha_AI_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:30.386584Z",
     "start_time": "2025-07-30T13:32:30.382508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#modifying metadata\n",
    "for chunk in chunks:\n",
    "    chunk.metadata={\n",
    "        'source':'MTS',\n",
    "        'page':chunk.metadata.get('page'),\n",
    "        'document_page':chunk.metadata.get('page_label'),\n",
    "        'total_doc_pages':chunk.metadata.get('total_pages'),\n",
    "    }\n",
    "print(chunks[1].metadata)\n"
   ],
   "id": "70c1fc61367840d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'MTS', 'page': 0, 'document_page': '1', 'total_doc_pages': 1}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:30.431042Z",
     "start_time": "2025-07-30T13:32:30.426996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(chunks)\n",
    "print(type(chunks))\n",
    "chunkContent=[]\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunkContent.append(chunk.page_content)\n",
    "\n",
    "\n",
    "print (type(chunkContent))"
   ],
   "id": "313c5f6d2f87c84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:30.552074Z",
     "start_time": "2025-07-30T13:32:30.476461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we create its embeddings\n",
    "#using the same embedding model\n",
    "embeddingResult=[]\n",
    "\n",
    "for chunk in chunks:\n",
    "    embeddingResult.append(embeddingModel.embed_query(chunk.page_content))\n",
    "\n",
    "\n",
    "\n",
    "value=embeddingResult[0][2]\n",
    "print(value)"
   ],
   "id": "ac75133e8f44c76a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07337682694196701\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    },
    "ExecuteTime": {
     "end_time": "2025-07-30T11:35:03.354197900Z",
     "start_time": "2025-07-30T11:35:03.342939900Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": "%%sql\n",
   "id": "a46afaf59efc39d5",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f7e5bb985da96cca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:33.270664Z",
     "start_time": "2025-07-30T13:32:30.569306Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -qU langchain langchain-pinecone langchain-openai",
   "id": "ecc1cf545dc11b69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Taha\\PycharmProjects\\LangchainAgent\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:33.414065Z",
     "start_time": "2025-07-30T13:32:33.286581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not pinecone_api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY is not set\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ],
   "id": "81dd74852e596c1f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:39.907150Z",
     "start_time": "2025-07-30T13:32:33.533449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "\n",
    "  # change if desired\n",
    "name=\"resumebot\"\n",
    "if not pc.has_index(name):\n",
    "    pc.create_index(\n",
    "        name=name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "Index = pc.Index(name)\n",
    "vector_store = PineconeVectorStore(index=Index, embedding=embeddingModel)\n",
    "vector_store.add_documents(chunks)\n",
    "\n",
    "#\n",
    "# vectorsToPass = [\n",
    "#     {\n",
    "#         \"id\": str(i),\n",
    "#         \"values\": embeddingResult\n",
    "#     }\n",
    "#     for i, chunk in enumerate(chunks)\n",
    "# ]\n",
    "#\n",
    "# Index.upsert(vectors=vectorsToPass)\n",
    "#\n",
    "\n"
   ],
   "id": "1dfee06b73ffa95b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dd3fba1c-fe29-41dc-afae-514eb0109e4b',\n",
       " '7f97128c-d18a-4946-908c-7f61741b65fd']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:40.284659Z",
     "start_time": "2025-07-30T13:32:39.925554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"machine learning\",\n",
    "    k=1,\n",
    "    metric=\"cosine\",\n",
    "\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ],
   "id": "ffb01c8e95c92d66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* This project demonstrated practical networking concepts and real-time device management as part of a computer networks \n",
      "course. About me \n",
      "Aspiring Machine Learning Intern and Computer Science student at Air University (2023–2027), with strong foundational knowledge in \n",
      "Python, C++, and backend development. Currently pursuing the Coursera Machine Learning Specialization by DeepLearning.AI. Highly \n",
      "motivated to apply and grow skills in real-world AI/ML projects through hands-on internship opportunities. [{'document_page': '1', 'page': 0.0, 'source': 'MTS', 'total_doc_pages': 1.0}]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:41.301634Z",
     "start_time": "2025-07-30T13:32:40.311759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_query =\"what is the experience do you have in machine learning?\"\n",
    "results = vector_store.similarity_search(user_query)\n",
    "results=vector_store.max_marginal_relevance_search(user_query)\n"
   ],
   "id": "e86601991dde402c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:41.639041Z",
     "start_time": "2025-07-30T13:32:41.318653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "question=\"\"\n",
    "promptTemplate = ChatPromptTemplate([\n",
    "    (\"system\", \"answer the question brifly from the context {Context} ,ACT as a TAHA's personal agent \"),\n",
    "\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# question=\"what is the experience do you have in machine learning?\"\n",
    "context_got=vector_store.max_marginal_relevance_search(question)\n",
    "type(context_got)\n"
   ],
   "id": "f3dfc0b62a496575",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:41.665218Z",
     "start_time": "2025-07-30T13:32:41.660925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"GEMINI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your Gemini API key: \")\n"
   ],
   "id": "6468f84b915617d9",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:32:44.055383Z",
     "start_time": "2025-07-30T13:32:41.692598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load docs\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load variables from .env\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    ")\n",
    "ourContext=\"\"\n",
    "for con in context_got:\n",
    "    ourContext+=con.page_content\n",
    "\n",
    "parser=StrOutputParser()\n",
    "\n",
    "chain=promptTemplate|llm|parser\n",
    "\n",
    "# FinalResponse=chain.invoke({\"Context\":ourContext,\"question\":question})\n",
    "# print(FinalResponse)"
   ],
   "id": "883113a462938eef",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-30T13:32:44.078192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow Jupyter event loop to work with Uvicorn\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def RAGapplication(query:str):\n",
    "    FinalResponse=chain.invoke({\"Context\":ourContext,\"question\":query})\n",
    "\n",
    "    return {\"response\":FinalResponse}\n",
    "\n",
    "# Start the server in the same cell\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ],
   "id": "d691de22c0f00646",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [12100]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "686c5878f87f69eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
